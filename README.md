<a name="readme-top"></a>

# Latent Collaboration in Multi-Agent Systems with KNN Cache Filtering

## üí° Introduction

This repository is based on the **LatentMAS** framework ([Zou et al., 2025](https://arxiv.org/abs/2511.20639)), a multi-agent reasoning framework that **moves agent collaboration from token space into the model's latent space**.

**Key Features:**
- **Efficient** multi-step reasoning with drastically fewer tokens
- **Training-free** latent-space alignment for stable generation
- **KNN-based KV cache filtering** for memory-efficient agent communication
- **Three selection strategies**: top-k similarity, bottom-k diversity, and random baseline
- Compatible with **any HuggingFace model**

This implementation extends the original LatentMAS with experimental KNN filtering capabilities for the KV cache, enabling more efficient memory usage during multi-agent collaboration.

## üìä Supported Datasets

This implementation supports the following datasets:
- **GSM8K**: Grade school math problems
- **GPQA (Diamond)**: Graduate-level science questions
- **MedQA**: Medical question answering

## üõ†Ô∏è Getting Started

### ‚öôÔ∏è Setup Environment Variables

We recommend setting your HF cache directory to avoid repeated downloads:

```bash
export HF_HOME=/path/to/huggingface
export TRANSFORMERS_CACHE=$HF_HOME
export HF_DATASETS_CACHE=$HF_HOME
```

Models and datasets will automatically be downloaded into `$HF_HOME`.

### üì¶ Install Packages

```bash
conda create -n latentmas python=3.10 -y
conda activate latentmas

pip install -r requirements.txt
```

## üöÄ Quick Start

### 1. Clone the repo

```bash
git clone https://github.com/YourRepo/LatentMAS.git
cd LatentMAS
```

### 2. Repository Structure

```
LatentMAS/
‚îÇ‚îÄ‚îÄ run.py                 # Main entry for experiments
‚îÇ‚îÄ‚îÄ models.py              # Wrapper for HF models + latent realignment
‚îÇ‚îÄ‚îÄ methods/
‚îÇ   ‚îú‚îÄ‚îÄ baseline.py        # Single-agent baseline
‚îÇ   ‚îú‚îÄ‚îÄ text_mas.py        # Token-space multi-agent method
‚îÇ   ‚îî‚îÄ‚îÄ latent_mas.py      # Latent-space multi-agent (with KNN filtering)
‚îÇ‚îÄ‚îÄ prompts.py             # Prompt constructors
‚îÇ‚îÄ‚îÄ data.py                # Dataset loaders (GSM8K, GPQA, MedQA)
‚îÇ‚îÄ‚îÄ data/                  # Provided data + figures
‚îÇ‚îÄ‚îÄ utils.py               # Answer parsing / timeout / helpers
‚îÇ‚îÄ‚îÄ example_logs/          # Example logs from LatentMAS
‚îÇ‚îÄ‚îÄ requirements.txt
```

## üß™ Running Experiments

### üîπ **Baseline (single model)**

```bash
python run.py --method baseline --model_name Qwen/Qwen3-4B --task gsm8k --max_samples 100
```

### üîπ **TextMAS (text-based multi-agent system)**

```bash
python run.py --method text_mas --model_name Qwen/Qwen3-4B --task gsm8k --prompt sequential --max_samples 100
```

### üîπ **LatentMAS (latent multi-agent system)**

```bash
python run.py --method latent_mas --model_name Qwen/Qwen3-4B --task gsm8k --latent_steps 10 --prompt sequential --max_samples 100
```

#### Key Parameters:

* **`--latent_steps`** ‚àà [0, 80]
  Number of latent reasoning steps per agent. Typically **10‚Äì20** works well.

* **`--latent_space_realign`**
  Enables latent‚Üíembedding alignment for better generation stability.

```bash
python run.py --method latent_mas --model_name Qwen/Qwen3-4B --task gsm8k --latent_steps 10 --latent_space_realign --max_samples 100
```

* **`--prompt`** ‚àà {`sequential`, `hierarchical`}
  Prompt structure for agent collaboration.

## üî¨ KNN Cache Filtering (Experimental)

This implementation includes experimental KNN-based filtering of the KV cache to reduce memory usage during agent-to-agent communication.

### Key KNN Parameters:

* **`--knn_filter`**
  Enable KNN filtering of the KV cache

* **`--knn_percentage`** (default: 0.8)
  Percentage of tokens to keep (0.0-1.0). E.g., 0.8 keeps 80% of the cache.

* **`--knn_min_keep`** (default: 5)
  Minimum number of recent tokens to always preserve, regardless of similarity.

* **`--knn_strategy`** ‚àà {`top`, `bottom`, `random`} (default: `top`)
  - **`top`**: Keep most similar tokens (semantic relevance)
  - **`bottom`**: Keep least similar tokens (diversity baseline)
  - **`random`**: Keep random tokens (control baseline)

### üß¨ KNN Filtering Examples

#### 1. Standard KNN: Keep 80% most similar tokens

```bash
python run.py \
  --method latent_mas \
  --model_name Qwen/Qwen3-4B \
  --task gsm8k \
  --latent_steps 10 \
  --max_samples 10 \
  --knn_filter \
  --knn_percentage 0.8 \
  --knn_strategy top
```

#### 2. Aggressive filtering: Keep only 50% most similar

```bash
python run.py \
  --method latent_mas \
  --model_name Qwen/Qwen3-4B \
  --task gpqa \
  --latent_steps 10 \
  --max_samples 10 \
  --knn_filter \
  --knn_percentage 0.5 \
  --knn_strategy top
```

#### 3. Diversity baseline: Keep 80% least similar tokens

```bash
python run.py \
  --method latent_mas \
  --model_name Qwen/Qwen3-4B \
  --task medqa \
  --latent_steps 10 \
  --max_samples 10 \
  --knn_filter \
  --knn_percentage 0.8 \
  --knn_strategy bottom
```

#### 4. Random baseline: Keep random 80% of tokens

```bash
python run.py \
  --method latent_mas \
  --model_name Qwen/Qwen3-4B \
  --task gsm8k \
  --latent_steps 10 \
  --max_samples 10 \
  --knn_filter \
  --knn_percentage 0.8 \
  --knn_strategy random
```

#### 5. Conservative filtering with larger minimum keep

```bash
python run.py \
  --method latent_mas \
  --model_name Qwen/Qwen3-4B \
  --task gsm8k \
  --latent_steps 10 \
  --max_samples 10 \
  --knn_filter \
  --knn_percentage 0.9 \
  --knn_min_keep 10 \
  --knn_strategy top
```

#### 6. Full experiment with all features

```bash
python run.py \
  --method latent_mas \
  --model_name Qwen/Qwen3-4B \
  --task gsm8k \
  --prompt hierarchical \
  --latent_steps 20 \
  --max_samples 100 \
  --latent_space_realign \
  --knn_filter \
  --knn_percentage 0.7 \
  --knn_min_keep 5 \
  --knn_strategy top \
  --temperature 0.6 \
  --seed 42
```

### üîç Understanding KNN Strategies

| Strategy | What it keeps | Use case |
|----------|--------------|----------|
| `top` (default) | Most semantically similar tokens to current query | Main approach - maximize relevance |
| `bottom` | Least similar tokens (diverse/orthogonal context) | Test if diversity > similarity |
| `random` | Random selection of tokens | Control for cache size reduction effect |

### üí° KNN Filtering Tips

1. **Start with default settings** (`--knn_percentage 0.8 --knn_strategy top`)
2. **Experiment with percentage**: Try 0.5, 0.7, 0.8, 0.9 to find the sweet spot
3. **Use `random` strategy** as a baseline to validate that similarity-based selection matters
4. **Adjust `knn_min_keep`** based on your latent_steps (e.g., 5-10 for most cases)
5. **Monitor accuracy vs memory tradeoff** - lower percentages save more memory but may hurt accuracy

## üìö Citation

This implementation is based on the LatentMAS paper. If you find this work helpful, please cite:

```
@article{zou2025latentmas,
  title={Latent Collaboration in Multi-Agent Systems},
  author={Zou, Jiaru and Yang, Xiyuan and Qiu, Ruizhong and Li, Gaotang and Tieu, Katherine and Lu, Pan and Shen, Ke and Tong, Hanghang and Choi, Yejin and He, Jingrui and Zou, James and Wang, Mengdi and Yang, Ling},
  journal={arXiv preprint arXiv:2511.20639},
  year={2025}
}
```

## ü§ù Acknowledgement

This code is based on the LatentMAS framework by [Zou et al., 2025](https://arxiv.org/abs/2511.20639). The KNN cache filtering extension was developed independently for research purposes.
